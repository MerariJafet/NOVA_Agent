#!/usr/bin/env python3
"""
Tests para el Sistema de Cach√© Inteligente - Sprint 3 D√≠a 3
"""

import sys
import os
import time
import tempfile
import shutil
import sqlite3
import hashlib
import json


# Simular las dependencias m√≠nimas para testing
class MockSettings:
    def __init__(self):
        self.db_path = ":memory:"
        self.model_profiles_path = "/tmp/test_model_profiles.json"


settings = MockSettings()


def init_test_db():
    """Inicializar base de datos de prueba en memoria."""
    conn = sqlite3.connect(settings.db_path)
    cursor = conn.cursor()

    # Crear tabla response_cache
    cursor.execute(
        """
        CREATE TABLE IF NOT EXISTS response_cache (
            cache_key TEXT PRIMARY KEY,
            query TEXT NOT NULL,
            model_name TEXT NOT NULL,
            response TEXT NOT NULL,
            metadata TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            expires_at TIMESTAMP,
            hit_count INTEGER DEFAULT 0,
            last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """
    )

    # Crear √≠ndices
    cursor.execute(
        "CREATE INDEX IF NOT EXISTS idx_response_cache_expires_at ON response_cache(expires_at)"
    )
    cursor.execute(
        "CREATE INDEX IF NOT EXISTS idx_response_cache_model ON response_cache(model_name)"
    )
    cursor.execute(
        "CREATE INDEX IF NOT EXISTS idx_response_cache_query_model ON response_cache(query, model_name)"
    )

    conn.commit()
    return conn


class CacheSystem:
    """Sistema de cach√© simplificado para testing."""

    def __init__(self, ttl_days=7):
        self.ttl_days = ttl_days
        self.conn = init_test_db()

    def _generate_cache_key(self, query, model_name, parameters=None):
        """Generar clave de cach√© √∫nica."""
        key_data = f"{query}|{model_name}"
        if parameters:
            key_data += f"|{json.dumps(parameters, sort_keys=True)}"
        return hashlib.sha256(key_data.encode()).hexdigest()

    def _get_expires_at(self):
        """Calcular fecha de expiraci√≥n."""
        return time.time() + (self.ttl_days * 24 * 60 * 60)

    def get_cached_response(self, query, model_name, parameters=None):
        """Obtener respuesta del cach√©."""
        cache_key = self._generate_cache_key(query, model_name, parameters)

        cursor = self.conn.cursor()
        cursor.execute(
            """
            SELECT response, metadata, hit_count, created_at, expires_at
            FROM response_cache
            WHERE cache_key = ? AND expires_at > ?
        """,
            (cache_key, time.time()),
        )

        row = cursor.fetchone()
        if row:
            response_json, metadata_json, hit_count, created_at, expires_at = row

            # Incrementar hit_count
            cursor.execute(
                """
                UPDATE response_cache
                SET hit_count = hit_count + 1, last_accessed = CURRENT_TIMESTAMP
                WHERE cache_key = ?
            """,
                (cache_key,),
            )
            self.conn.commit()

            response = json.loads(response_json)
            metadata = json.loads(metadata_json) if metadata_json else {}

            return {
                "cached": True,
                "response": response,
                "metadata": metadata,
                "hit_count": hit_count + 1,
                "created_at": created_at,
                "expires_at": expires_at,
            }

        return None

    def save_to_cache(
        self, query, model_name, response, parameters=None, metadata=None
    ):
        """Guardar respuesta en cach√©."""
        cache_key = self._generate_cache_key(query, model_name, parameters)
        expires_at = self._get_expires_at()

        response_json = json.dumps(response)
        metadata_json = json.dumps(metadata or {})

        cursor = self.conn.cursor()
        cursor.execute(
            """
            INSERT OR REPLACE INTO response_cache
            (cache_key, query, model_name, response, metadata, expires_at, hit_count)
            VALUES (?, ?, ?, ?, ?, ?, 0)
        """,
            (cache_key, query, model_name, response_json, metadata_json, expires_at),
        )

        self.conn.commit()
        return cache_key

    def invalidate_cache(self, model_name=None, query=None):
        """Invalidar entradas del cach√©."""
        cursor = self.conn.cursor()

        if model_name and query:
            cursor.execute(
                "DELETE FROM response_cache WHERE model_name = ? AND query = ?",
                (model_name, query),
            )
        elif model_name:
            cursor.execute(
                "DELETE FROM response_cache WHERE model_name = ?", (model_name,)
            )
        elif query:
            cursor.execute("DELETE FROM response_cache WHERE query = ?", (query,))
        else:
            cursor.execute("DELETE FROM response_cache")

        deleted_count = cursor.rowcount
        self.conn.commit()
        return deleted_count

    def cleanup_expired(self):
        """Limpiar entradas expiradas."""
        cursor = self.conn.cursor()
        cursor.execute(
            "DELETE FROM response_cache WHERE expires_at <= ?", (time.time(),)
        )
        deleted_count = cursor.rowcount
        self.conn.commit()
        return deleted_count

    def get_cache_stats(self):
        """Obtener estad√≠sticas del cach√©."""
        cursor = self.conn.cursor()

        # Total de entradas
        cursor.execute("SELECT COUNT(*) FROM response_cache")
        total_entries = cursor.fetchone()[0]

        # Entradas v√°lidas (no expiradas)
        cursor.execute(
            "SELECT COUNT(*) FROM response_cache WHERE expires_at > ?", (time.time(),)
        )
        valid_entries = cursor.fetchone()[0]

        # Total de hits
        cursor.execute("SELECT SUM(hit_count) FROM response_cache")
        total_hits = cursor.fetchone()[0] or 0

        # Calcular hit rate (si hay entradas v√°lidas)
        hit_rate = (total_hits / valid_entries * 100) if valid_entries > 0 else 0

        return {
            "total_entries": total_entries,
            "valid_entries": valid_entries,
            "expired_entries": total_entries - valid_entries,
            "total_hits": total_hits,
            "hit_rate_percent": hit_rate,
        }


def setup_test_environment():
    """Configurar entorno de prueba con archivos temporales."""
    # Crear directorios temporales
    temp_dir = tempfile.mkdtemp()
    temp_data_dir = os.path.join(temp_dir, "data")
    os.makedirs(temp_data_dir)

    # Configurar settings temporales
    original_db_path = settings.db_path
    settings.db_path = os.path.join(temp_data_dir, "test_cache.db")

    # Inicializar DB de prueba
    init_test_db()

    return {"temp_dir": temp_dir, "original_db_path": original_db_path}


def cleanup_test_environment(env):
    """Limpiar entorno de prueba."""
    settings.db_path = env["original_db_path"]
    shutil.rmtree(env["temp_dir"], ignore_errors=True)


def test_cache_basic_operations():
    """Test b√°sico de operaciones del cach√©."""
    env = setup_test_environment()

    try:
        cache = CacheSystem(ttl_days=7)

        # Test 1: Cache miss inicial
        result = cache.get_cached_response("¬øQu√© es la IA?", "dolphin-mistral:7b")
        assert result is None, "Deber√≠a ser cache miss inicialmente"
        print("‚úÖ Cache miss inicial correcto")

        # Test 2: Guardar en cach√©
        response_data = {"text": "La IA es inteligencia artificial..."}
        cache_key = cache.save_to_cache(
            query="¬øQu√© es la IA?",
            model_name="dolphin-mistral:7b",
            response=response_data,
        )
        assert cache_key is not None, "Deber√≠a generar una cache_key"
        print("‚úÖ Guardado en cach√© exitoso")

        # Test 3: Cache hit
        start_time = time.time()
        result = cache.get_cached_response("¬øQu√© es la IA?", "dolphin-mistral:7b")
        hit_time = time.time() - start_time

        assert result is not None, "Deber√≠a ser cache hit"
        assert result["cached"], "Deber√≠a marcarse como cached"
        assert (
            hit_time < 0.05
        ), f"Cache hit deber√≠a ser <50ms, fue {hit_time*1000:.2f}ms"
        assert (
            result["response"]["text"] == response_data["text"]
        ), "Respuesta deber√≠a coincidir"
        print(f"‚úÖ Cache hit en {hit_time*1000:.2f}ms (<50ms requerido)")

        # Test 4: Hit count incrementa
        result2 = cache.get_cached_response("¬øQu√© es la IA?", "dolphin-mistral:7b")
        assert (
            result2["hit_count"] == result["hit_count"] + 1
        ), "Hit count deber√≠a incrementarse"
        print("‚úÖ Hit count se incrementa correctamente")

        print("‚úÖ Test b√°sico de operaciones completado")

    finally:
        cleanup_test_environment(env)


def test_cache_expiration():
    """Test de expiraci√≥n del cach√©."""
    env = setup_test_environment()

    try:
        # Crear cach√© con TTL muy corto (0.1 segundos para test r√°pido)
        cache = CacheSystem(ttl_days=1 / 86400 / 10)  # 0.1 segundos

        # Guardar en cach√©
        cache.save_to_cache("test query", "test_model", {"text": "test response"})

        # Verificar que existe
        result = cache.get_cached_response("test query", "test_model")
        assert result is not None, "Deber√≠a existir inicialmente"
        print("‚úÖ Entrada guardada correctamente")

        # Esperar a que expire (0.15 segundos)
        time.sleep(0.15)

        # Verificar que expir√≥
        result = cache.get_cached_response("test query", "test_model")
        assert result is None, "Deber√≠a haber expirado"
        print("‚úÖ Entrada expir√≥ correctamente")

        # Limpiar expiradas
        cleaned = cache.cleanup_expired()
        assert cleaned >= 1, "Deber√≠a limpiar al menos 1 entrada"
        print(f"‚úÖ Limpieza autom√°tica: {cleaned} entradas eliminadas")

        print("‚úÖ Test de expiraci√≥n completado")

    finally:
        cleanup_test_environment(env)


def test_cache_invalidation():
    """Test de invalidaci√≥n del cach√©."""
    env = setup_test_environment()

    try:
        cache = CacheSystem(ttl_days=7)

        # Guardar varias entradas
        cache.save_to_cache("query1", "model1", {"text": "response1"})
        cache.save_to_cache("query2", "model1", {"text": "response2"})
        cache.save_to_cache("query3", "model2", {"text": "response3"})

        # Verificar que existen
        assert cache.get_cached_response("query1", "model1") is not None
        assert cache.get_cached_response("query2", "model1") is not None
        assert cache.get_cached_response("query3", "model2") is not None
        print("‚úÖ Todas las entradas guardadas")

        # Invalidar por modelo
        invalidated = cache.invalidate_cache(model_name="model1")
        assert invalidated == 2, "Deber√≠a invalidar 2 entradas de model1"
        print(f"‚úÖ Invalidaci√≥n por modelo: {invalidated} entradas")

        # Verificar que las de model1 ya no existen
        assert cache.get_cached_response("query1", "model1") is None
        assert cache.get_cached_response("query2", "model1") is None
        # Pero model2 s√≠ existe
        assert cache.get_cached_response("query3", "model2") is not None
        print("‚úÖ Invalidaci√≥n selectiva correcta")

        print("‚úÖ Test de invalidaci√≥n completado")

    finally:
        cleanup_test_environment(env)


def test_cache_performance():
    """Test de performance del cach√©."""
    env = setup_test_environment()

    try:
        cache = CacheSystem(ttl_days=7)

        # Preparar datos de prueba
        test_queries = [
            f"¬øQu√© es {topic}?"
            for topic in [
                "Python",
                "Machine Learning",
                "Deep Learning",
                "Neural Networks",
                "Computer Vision",
            ]
        ]

        # Test de cache misses (primera vez)
        print("üìä Midiendo performance de cache misses...")
        miss_times = []

        for query in test_queries:
            start_time = time.time()
            result = cache.get_cached_response(query, "dolphin-mistral:7b")
            miss_time = time.time() - start_time
            miss_times.append(miss_time)

            # Guardar en cach√© para pr√≥ximos tests
            cache.save_to_cache(
                query, "dolphin-mistral:7b", {"text": f"Respuesta sobre {query}"}
            )

        avg_miss_time = sum(miss_times) / len(miss_times)
        print(f"   Cache miss promedio: {avg_miss_time*1000:.2f}ms")

        # Test de cache hits (segunda vez)
        print("üìä Midiendo performance de cache hits...")
        hit_times = []

        for query in test_queries:
            start_time = time.time()
            result = cache.get_cached_response(query, "dolphin-mistral:7b")
            hit_time = time.time() - start_time
            hit_times.append(hit_time)

            assert result is not None, f"Cache hit fall√≥ para: {query}"
            assert hit_time < 0.05, f"Cache hit demasiado lento: {hit_time*1000:.2f}ms"

        avg_hit_time = sum(hit_times) / len(hit_times)
        print(f"   Cache hit promedio: {avg_hit_time*1000:.2f}ms")

        # Verificar requerimientos
        assert (
            avg_hit_time < 0.05
        ), f"Cache hits deben ser <50ms, fueron {avg_hit_time*1000:.2f}ms"
        print("‚úÖ Performance de cach√© cumple requerimientos (<50ms)")

        # Calcular hit rate
        stats = cache.get_cache_stats()
        hit_rate = stats["hit_rate_percent"]
        print(f"üéØ Hit rate actual: {hit_rate:.1f}%")

        print("‚úÖ Test de performance completado")

    finally:
        cleanup_test_environment(env)


def test_cache_stats():
    """Test de estad√≠sticas del cach√©."""
    env = setup_test_environment()

    try:
        cache = CacheSystem(ttl_days=7)

        # Estado inicial
        stats = cache.get_cache_stats()
        assert stats["total_entries"] == 0, "Deber√≠a empezar vac√≠o"
        print("‚úÖ Estado inicial correcto")

        # Agregar algunas entradas
        for i in range(5):
            cache.save_to_cache(f"query{i}", "model1", {"text": f"response{i}"})

        # Hacer algunos hits
        for i in range(3):
            cache.get_cached_response(f"query{i}", "model1")

        # Verificar estad√≠sticas
        stats = cache.get_cache_stats()
        assert stats["total_entries"] == 5, "Deber√≠a tener 5 entradas"
        assert stats["valid_entries"] == 5, "Todas deber√≠an ser v√°lidas"
        assert stats["total_hits"] == 3, "Deber√≠a tener 3 hits"
        assert stats["hit_rate_percent"] == 60.0, "Hit rate deber√≠a ser 60%"
        print("‚úÖ Estad√≠sticas calculadas correctamente")

        print("‚úÖ Test de estad√≠sticas completado")

    finally:
        cleanup_test_environment(env)


def test_hit_rate_requirement():
    """Test espec√≠fico para validar >90% hit rate en consultas repetidas."""
    env = setup_test_environment()

    try:
        cache = CacheSystem(ttl_days=7)

        # Simular 10 consultas repetidas como requiere el Sprint 3 D√≠a 3
        test_query = "¬øQu√© es la inteligencia artificial?"
        model_name = "dolphin-mistral:7b"

        total_requests = 10
        expected_hits = 9  # Primera es miss, las 9 siguientes son hits
        actual_hits = 0

        print(f"üìä Probando {total_requests} consultas repetidas...")

        for i in range(total_requests):
            result = cache.get_cached_response(test_query, model_name)

            if i == 0:
                # Primera consulta deber√≠a ser miss
                assert result is None, "Primera consulta deber√≠a ser cache miss"
                # Guardar en cach√©
                cache.save_to_cache(test_query, model_name, {"text": "La IA es..."})
                print(f"   Consulta {i+1}: MISS (guardado en cach√©)")
            else:
                # Consultas siguientes deber√≠an ser hits
                if result is not None:
                    actual_hits += 1
                    print(
                        f"   Consulta {i+1}: HIT ({result['hit_count']} hits totales)"
                    )
                else:
                    print(f"   Consulta {i+1}: MISS (inesperado)")

        # Calcular hit rate
        hit_rate = (
            actual_hits / (total_requests - 1)
        ) * 100  # Excluimos la primera consulta

        print(
            f"üéØ Resultado: {actual_hits}/{total_requests-1} hits = {hit_rate:.1f}% hit rate"
        )

        # Validar requerimiento >90%
        assert hit_rate >= 90.0, f"Hit rate debe ser >=90%, fue {hit_rate:.1f}%"
        assert (
            actual_hits == expected_hits
        ), f"Deber√≠an ser {expected_hits} hits, fueron {actual_hits}"

        print("‚úÖ Hit rate >90% en consultas repetidas ‚úì")
        print("‚úÖ Requerimiento del Sprint 3 D√≠a 3 cumplido ‚úì")

        print("‚úÖ Test de hit rate completado")

    finally:
        cleanup_test_environment(env)


def run_all_tests():
    """Ejecutar todos los tests."""
    print("üöÄ Ejecutando tests del Sistema de Cach√© Inteligente...")
    print("=" * 60)

    try:
        test_cache_basic_operations()
        test_cache_expiration()
        test_cache_invalidation()
        test_cache_performance()
        test_cache_stats()
        test_hit_rate_requirement()

        print("=" * 60)
        print("üéâ Todos los tests pasaron exitosamente!")
        print("‚úÖ Cach√© inteligente funcionando correctamente")
        print("‚úÖ Cache hits <50ms ‚úì")
        print("‚úÖ TTL de 7 d√≠as ‚úì")
        print("‚úÖ Hit counting ‚úì")
        print("‚úÖ Invalidaci√≥n autom√°tica ‚úì")
        print("‚úÖ Hit rate >90% en consultas repetidas ‚úì")
        return True

    except Exception as e:
        print(f"‚ùå Error en tests: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
