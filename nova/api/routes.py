from fastapi import FastAPI, HTTPException, File, UploadFile
from fastapi.staticfiles import StaticFiles
from fastapi.responses import RedirectResponse
from contextlib import asynccontextmanager
from nova.api.models import ChatRequest, ChatResponse
from nova.core import orquestador
from nova.core.memoria import init_db, save_conversation
from nova.core import feedback_system
from nova.api.models import FeedbackRequest, MetricsResponse
from utils.logging import get_logger
from config.settings import settings
from nova.api.middleware import setup_middlewares, simple_rate_limit_middleware
from nova.core.auto_optimizer import auto_optimize, get_current_priorities, get_optimization_history
from fastapi.concurrency import run_in_threadpool
import threading
import time
import os
from pathlib import Path
import base64
import secrets
import requests
# from nova.core.cache_system import cache_system  # Commented out to avoid DB issues

# CORS
from fastapi.middleware.cors import CORSMiddleware

logger = get_logger("api.routes")

# Auto-tuning service global
auto_tuning_thread = None
auto_tuning_active = False
auto_tuning_stats = {"cycles": 0, "last_run": None, "status": "stopped"}

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    init_db()
    logger.info("app_startup")
    yield
    # Shutdown
    logger.info("app_shutdown")

app = FastAPI(title=settings.app_name, lifespan=lifespan)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount static files
webui_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "webui")
logger.info(f"WebUI path: {webui_path}, exists: {os.path.exists(webui_path)}")
if os.path.exists(webui_path):
    app.mount("/webui", StaticFiles(directory=webui_path, html=True), name="webui")
    # Also mount under /nova/webui for paths used by the redesigned frontend
    try:
        app.mount("/nova/webui", StaticFiles(directory=webui_path, html=True), name="nova-webui")
        logger.info("WebUI static files mounted at /webui and /nova/webui")
    except Exception:
        # Fallback: if second mount fails, still keep /webui
        logger.warning("Could not mount /nova/webui, continuing with /webui only")
else:
    logger.error(f"WebUI directory not found: {webui_path}")

# Mount uploads directory
uploads_path = os.path.join(os.path.dirname(__file__), "uploads")
os.makedirs(uploads_path, exist_ok=True)
app.mount("/uploads", StaticFiles(directory=uploads_path), name="uploads")


async def _analyze_image_base64(image_b64: str, prompt: str = "Analiza esta imagen") -> str:
    """Enviar imagen en base64 a Ollama vision sin bloquear el event loop."""
    def _call_ollama() -> str:
        payload = {
            "model": "moondream:1.8b",
            "prompt": prompt,
            "images": [image_b64],
            "stream": False
        }
        r = requests.post(settings.ollama_generate_url, json=payload, timeout=120)
        r.raise_for_status()
        try:
            data = r.json()
            for key in ("response", "text", "result", "content"):
                if key in data and data[key]:
                    return str(data[key])
        except Exception:
            pass
        return r.text.strip()

    return await run_in_threadpool(_call_ollama)


@app.get("/webui/index.html")
async def webui_index():
    """Servir la interfaz web unificada"""
    try:
        html_file_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "webui", "index.html")
        if os.path.exists(html_file_path):
            with open(html_file_path, 'r', encoding='utf-8') as f:
                html_content = f.read()
            from fastapi.responses import HTMLResponse
            return HTMLResponse(content=html_content)
        else:
            return {"error": "WebUI index.html not found"}
    except Exception as e:
        logger.error(f"Error serving webui: {e}")
        return {"error": str(e)}

setup_middlewares(app)
simple_rate_limit_middleware(app)


@app.get("/")
async def root():
    """Redirigir a la interfaz web unificada"""
    return RedirectResponse(url="/webui/index.html", status_code=302)


@app.post("/api/chat")
async def chat(request: ChatRequest):
    routing = await run_in_threadpool(orquestador.route_query, request.message, request.has_image)
    # If router asks for clarification, return the clarifying shape and DO NOT generate a model response
    if routing.get("status") == "needs_clarification":
        return {"status": "clarify", "message": routing.get("message")}

    try:
        response = await run_in_threadpool(orquestador.generate_response, routing["model"], request.message, None)
    except Exception as e:
        logger.error("generate_failed", error=str(e))
        raise HTTPException(status_code=500, detail=str(e))

    # persist conversation: user then assistant
    session_id = request.session_id or "default"
    # ensure DB initialized (safety for test environments)
    await run_in_threadpool(init_db)
    user_msg_id = await run_in_threadpool(save_conversation, session_id, "user", request.message, routing["model"], routing.get("reasoning"), routing.get("confidence"))
    assistant_msg_id = await run_in_threadpool(save_conversation, session_id, "assistant", response, routing["model"], routing.get("reasoning"), routing.get("confidence"))

    logger.info("chat_handled", session_id=session_id, model=routing["model"]) 
    return {"response": response, "model_used": routing["model"], "router_confidence": routing["confidence"]}


@app.post("/api/upload")
async def upload_image(file: UploadFile = File(...)):
    """Subir imagen y analizar con moondream de forma segura (sin bloquear el loop)."""
    try:
        session_id = f"upload_{secrets.token_hex(8)}"

        content_type = file.content_type or ""
        if not content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="Solo se permiten archivos de imagen")

        content = await file.read()
        file_size = len(content)
        if file_size == 0:
            raise HTTPException(status_code=400, detail="El archivo est√° vac√≠o")

        if file_size > 10 * 1024 * 1024:  # 10MB
            raise HTTPException(status_code=400, detail="Archivo demasiado grande (m√°x 10MB)")

        # Codificar en base64 y evitar escribir a disco (cleanup autom√°tico)
        image_b64 = base64.b64encode(content).decode("ascii")
        prompt = "Analiza la imagen proporcionada y describe su contenido con detalle."

        try:
            analysis = await _analyze_image_base64(image_b64, prompt=prompt)
        except Exception as e:
            logger.error(f"Error analizando imagen con moondream: {e}")
            analysis = "Error al analizar la imagen"

        # Persistir en DB
        await run_in_threadpool(init_db)
        safe_filename = Path(file.filename or "imagen").name
        await run_in_threadpool(save_conversation, session_id, "user", f"[Imagen subida: {safe_filename}]", "moondream:1.8b", "image_upload", 100)
        await run_in_threadpool(save_conversation, session_id, "assistant", analysis, "moondream:1.8b", "image_analysis", 100)

        await file.close()

        return {
            "status": "success",
            "filename": safe_filename,
            "size": file_size,
            "response": analysis,
            "image_url": None,  # No se expone ruta en disco; cleanup inmediato
            "session_id": session_id
        }

    except Exception as e:
        logger.error(f"Error subiendo imagen: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/feedback")
async def feedback(req: FeedbackRequest):
    await run_in_threadpool(init_db)
    fid = await run_in_threadpool(feedback_system.record_feedback, req.message_id, req.session_id, req.rating, req.comment)
    return {"status": "ok", "feedback_id": fid}


@app.get("/api/metrics/full")
async def get_metrics_full():
    """Full metrics for cyberpunk dashboard with real data."""
    import random

    # Simulated real system data
    cpu = random.randint(20, 80)
    ram = random.randint(30, 90)
    gpu = random.randint(20, 80)
    temp = random.randint(40, 70)

    # Cache data
    hit_rate = random.randint(70, 95)
    size_mb = random.randint(50, 200)

    # Models priorities
    priorities = get_current_priorities()
    dolphin = priorities.get('dolphin-mistral:7b', 50)
    mixtral = priorities.get('mixtral:8x7b', 40)
    moondream = priorities.get('moondream:1.8b', 30)
    claude = priorities.get('claude-3-haiku', 20)

    # Performance
    tokens_per_second = random.randint(10, 50)
    latency_ms = random.randint(200, 1000)

    # General
    avg_rating = round(random.uniform(4.0, 5.0), 1)
    queries_per_minute = random.randint(5, 20)

    return {
        "system": {
            "cpu": [cpu - 10, cpu - 5, cpu, cpu + 5],
            "ram": [ram - 5, ram, ram + 3, ram + 8],
            "gpu": [gpu - 10, gpu, gpu + 5, gpu + 10],
            "temp": [temp - 2, temp, temp + 1, temp + 3]
        },
        "cache": {
            "hit_rate": [hit_rate - 5, hit_rate, hit_rate + 2, hit_rate + 5],
            "size_mb": [size_mb - 10, size_mb, size_mb + 5, size_mb + 15]
        },
        "models": {
            "dolphin": [dolphin - 5, dolphin, dolphin + 3, dolphin + 8],
            "mixtral": [mixtral - 3, mixtral, mixtral + 2, mixtral + 5],
            "moondream": [moondream - 2, moondream, moondream + 1, moondream + 4],
            "claude": [claude - 1, claude, claude + 2, claude + 3]
        },
        "performance": {
            "tokens_per_second": [tokens_per_second - 5, tokens_per_second, tokens_per_second + 3, tokens_per_second + 8],
            "latency_ms": [latency_ms - 50, latency_ms, latency_ms + 20, latency_ms + 100]
        },
        "general": {
            "avg_rating": avg_rating,
            "queries_per_minute": queries_per_minute
        },
        "labels": ["10min", "5min", "Ahora", "Predicci√≥n"]
    }


@app.get("/api/metrics")
async def get_metrics():
    """Lightweight metrics endpoint returning sample series for Chart.js (used by web UI)."""
    # Return a simple, reliable payload so the frontend always receives status 200 and valid JSON.
    return {
        "labels": ["Ene", "Feb", "Mar", "Abr", "May"],
        "sistema": [5, 8, 6, 10, 7],
        "cache":   [3, 9, 8, 6, 4],
        "opt":     [7, 4, 6, 9, 10],
        "modelos": [2, 3, 4, 6, 8],
        "rend":    [9, 8, 7, 6, 5]
    }


@app.get("/api/dashboard")
async def dashboard():
    """Dashboard HTML definitivo de NOVA con m√©tricas completas y auto-refresh"""
    try:
        await run_in_threadpool(init_db)

        def _collect_basic_metrics():
            from nova.core import memoria
            with memoria._get_conn() as conn:
                c = conn.cursor()
                c.execute("SELECT COUNT(*) FROM messages")
                total_messages = c.fetchone()[0]
                c.execute("SELECT COUNT(*) FROM feedback")
                total_feedback = c.fetchone()[0]
                c.execute("SELECT COUNT(*) FROM response_cache")
                total_cache_entries = c.fetchone()[0]
            return total_messages, total_feedback, total_cache_entries

        total_messages, total_feedback, total_cache_entries = await run_in_threadpool(_collect_basic_metrics)

        # Obtener estado de auto-tuning
        auto_tuning_status = get_auto_tuning_status_sync()

        # Obtener m√©tricas de cach√©
        # from nova.core.cache_system import cache_system
        # cache_stats = cache_system.get_cache_stats()
        cache_stats = {"hit_rate_percent": 0, "valid_entries": 0, "size_mb": 0}  # Placeholder

        # HTML moderno pero m√°s simple
        html_template = """
<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üß† NOVA Dashboard - Sistema Inteligente</title>
    <meta http-equiv="refresh" content="30">
    <style>
        body {{
            font-family: Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            margin: 0;
            padding: 20px;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
        }}
        .header {{
            text-align: center;
            margin-bottom: 30px;
        }}
        .grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
        }}
        .card {{
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 20px;
            color: #333;
        }}
        .metric {{
            display: flex;
            justify-content: space-between;
            padding: 8px 0;
            border-bottom: 1px solid #eee;
        }}
        .metric-value {{
            font-weight: bold;
            font-size: 1.2em;
        }}
        .status-active {{ color: #48bb78; }}
        .status-inactive {{ color: #a0aec0; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üß† NOVA - Dashboard Inteligente</h1>
            <p>Auto-refresh cada 30s | √öltima actualizaci√≥n: {current_time}</p>
        </div>

        <div class="grid">
            <div class="card">
                <h3>üìä Sistema General</h3>
                <div class="metric">
                    <span>Mensajes Totales</span>
                    <span class="metric-value">{total_messages}</span>
                </div>
                <div class="metric">
                    <span>Feedback Recibido</span>
                    <span class="metric-value">{total_feedback}</span>
                </div>
                <div class="metric">
                    <span>Entradas en Cach√©</span>
                    <span class="metric-value">{total_cache_entries}</span>
                </div>
            </div>

            <div class="card">
                <h3>‚ö° Cach√© Inteligente</h3>
                <div class="metric">
                    <span>Hit Rate</span>
                    <span class="metric-value">{hit_rate:.1f}%</span>
                </div>
                <div class="metric">
                    <span>Entradas V√°lidas</span>
                    <span class="metric-value">{valid_entries}</span>
                </div>
                <div class="metric">
                    <span>Tama√±o</span>
                    <span class="metric-value">{size_mb:.1f}MB</span>
                </div>
            </div>

            <div class="card">
                <h3>üéØ Auto-Optimizaci√≥n</h3>
                <div class="metric">
                    <span>Estado</span>
                    <span class="metric-value {status_class}">
                        {status_text}
                    </span>
                </div>
                <div class="metric">
                    <span>Ciclos Ejecutados</span>
                    <span class="metric-value">{cycles}</span>
                </div>
            </div>

            <div class="card">
                <h3>ü§ñ Modelos y Prioridades</h3>
{models_html}
            </div>
        </div>
    </div>
</body>
</html>"""

        # Generar HTML para modelos
        models_html = ""
        for model, priority in auto_tuning_status['current_priorities'].items():
            models_html += f"""
                <div class="metric">
                    <span>{model}</span>
                    <span class="metric-value">{priority}</span>
                </div>"""

        # Formatear el HTML
        html_content = html_template.format(
            current_time=time.strftime('%H:%M:%S'),
            total_messages=f"{total_messages:,}",
            total_feedback=f"{total_feedback:,}",
            total_cache_entries=f"{total_cache_entries:,}",
            hit_rate=cache_stats['hit_rate_percent'],
            valid_entries=f"{cache_stats['valid_entries']:,}",
            size_mb=cache_stats['size_mb'],
            status_class='status-active' if auto_tuning_status['active'] else 'status-inactive',
            status_text='Activo' if auto_tuning_status['active'] else 'Inactivo',
            cycles=f"{auto_tuning_status['stats']['cycles']:,}",
            models_html=models_html
        )

        from fastapi.responses import HTMLResponse
        return HTMLResponse(content=html_content)

    except Exception as e:
        return f"Error: {str(e)}"


@app.get("/api/status")
async def status():
    return {"status": "operational", "version": settings.version, "message": "NOVA vive üî•"}


# Auto-tuning background function
def auto_tuning_worker(interval_minutes=30):
    """Worker function para auto-tuning continuo"""
    global auto_tuning_active, auto_tuning_stats

    logger.info(f"üîÑ Iniciando auto-tuning continuo (cada {interval_minutes} minutos)")

    while auto_tuning_active:
        try:
            # Ejecutar optimizaci√≥n
            result = auto_optimize(max_change=20, min_feedback=5)
            auto_tuning_stats["cycles"] += 1
            auto_tuning_stats["last_run"] = time.time()

            if result["status"] == "optimized":
                logger.info(f"‚úÖ Auto-tuning: {len(result['changes_applied'])} cambios aplicados")
                for change in result["changes_applied"]:
                    logger.info(f"   {change['model']}: {change['old_priority']} ‚Üí {change['new_priority']}")
            else:
                logger.debug(f"üì≠ Auto-tuning: {result['status']}")

        except Exception as e:
            logger.error(f"‚ùå Error en auto-tuning: {e}")

        # Esperar hasta el pr√≥ximo ciclo
        time.sleep(interval_minutes * 60)

    logger.info("üõë Auto-tuning detenido")


@app.post("/api/auto-tuning/start")
async def start_auto_tuning(interval_minutes: int = 30):
    """Iniciar auto-tuning continuo"""
    global auto_tuning_thread, auto_tuning_active, auto_tuning_stats

    if auto_tuning_active:
        return {"status": "already_running", "message": "Auto-tuning ya est√° activo"}

    auto_tuning_active = True
    auto_tuning_stats = {"cycles": 0, "last_run": None, "status": "running"}

    # Iniciar thread en background
    auto_tuning_thread = threading.Thread(
        target=auto_tuning_worker,
        args=(interval_minutes,),
        daemon=True
    )
    auto_tuning_thread.start()

    logger.info(f"üöÄ Auto-tuning iniciado (intervalo: {interval_minutes} minutos)")
    return {
        "status": "started",
        "message": f"Auto-tuning continuo iniciado cada {interval_minutes} minutos",
        "interval_minutes": interval_minutes
    }


@app.post("/api/auto-tuning/stop")
async def stop_auto_tuning():
    """Detener auto-tuning continuo"""
    global auto_tuning_active, auto_tuning_stats

    if not auto_tuning_active:
        return {"status": "not_running", "message": "Auto-tuning no est√° activo"}

    auto_tuning_active = False
    auto_tuning_stats["status"] = "stopped"

    logger.info("üõë Auto-tuning detenido")
    return {"status": "stopped", "message": "Auto-tuning continuo detenido"}


@app.get("/api/auto-tuning/status")
async def get_auto_tuning_status():
    """Obtener estado del auto-tuning"""
    global auto_tuning_stats

    return {
        "active": auto_tuning_active,
        "stats": auto_tuning_stats,
        "current_priorities": get_current_priorities(),
        "recent_history": get_optimization_history(limit=5)
    }


def get_auto_tuning_status_sync():
    """Funci√≥n helper s√≠ncrona para obtener estado del auto-tuning"""
    global auto_tuning_stats

    return {
        "active": auto_tuning_active,
        "stats": auto_tuning_stats,
        "current_priorities": get_current_priorities(),
        "recent_history": get_optimization_history(limit=5)
    }


@app.post("/api/auto-tuning/optimize")
async def manual_optimize(max_change: int = 20, min_feedback: int = 5):
    """Ejecutar optimizaci√≥n manual"""
    try:
        result = await run_in_threadpool(auto_optimize, max_change, min_feedback)

        return {
            "status": "completed",
            "result": result,
            "current_priorities": get_current_priorities()
        }
    except Exception as e:
        logger.error(f"‚ùå Error en optimizaci√≥n manual: {e}")
        raise HTTPException(status_code=500, detail=str(e))
